model:
  arch: minigpt4
  model_type: pretrain_vicuna0


datasets:
  laion:
    batch_size: 64
    vis_processor:
      train:
        name: "blip2_image_train"
        image_size: 224
    text_processor:
      train:
        name: "blip_caption"
    sample_ratio: 115
  cc_sbu:
    batch_size: 64
    vis_processor:
        train:
          name: "blip2_image_train"
          image_size: 224
    text_processor:
        train:
          name: "blip_caption"
    sample_ratio: 14


run:
  task: image_text_pretrain
  # optimizer
  lr_sched: "linear_warmup_cosine_lr"
  init_lr: 1e-4
  min_lr: 8e-5
  warmup_lr: 1e-6

  weight_decay: 0.05
  max_epoch: 4
  num_workers: 15
  warmup_steps: 5000
  iters_per_epoch: 5000

  seed: 42
  output_dir: "output/minigpt4_stage1_pretrain"

  amp: True
  resume_ckpt_path: null

  evaluate: False 
  train_splits: ["train"]

  device: "cuda"
  world_size: 1
  dist_url: "env://"
  distributed: True
  dist_backend: deepspeed
  ds_config:
    "train_batch_size": 16,
    "steps_per_print": 2000,
    "optimizer":
        "type": "Adam"
        "params":
            "lr": 0.001
            "betas": [
              0.8,
              0.999
            ]
            "eps": 1e-8
            "weight_decay": 3e-7
    "scheduler":
        "type": "WarmupLR"
        "params":
            "warmup_min_lr": 0
            "warmup_max_lr": 0.001
            "warmup_num_steps": 1000
    "gradient_clipping": 1.0
    "prescale_gradients": False
    "bf16":
        "enabled": False
    "fp16":
        "enabled": False
        "fp16_master_weights_and_grads": False
        "loss_scale": 0
        "loss_scale_window": 500
        "hysteresis": 2
        "min_loss_scale": 1
        "initial_scale_power": 15
    "wall_clock_breakdown": False
    "zero_optimization":
         "stage": args.stage
         "allgather_partitions": True
         "reduce_scatter": True
         "allgather_bucket_size": 50000000
         "reduce_bucket_size": 50000000
         "overlap_comm": True
         "contiguous_gradients": True
         "cpu_offload": False
  wandb_log: True
  job_name: minigpt4_pretrain